########################
## Basic parameters

## Sample information file with five columns: id / name / group / fq1 / fq2
src_sampleInfo	= "sample.tsv"

## Genome folder depending on platform: CCHMC:HPC vs my desktop
import socket
hostname = socket.gethostname()	
if( hostname == "EA19-00359" ):
	# my desktop
	genomeFa	= "/Users/limc8h/Research/Common_Data/hg38/genome/genome.fa"
	chrom_size	= "/Users/limc8h/Research/Common_Data/hg38/chrom.sizes"
	peak_mask	= "/Users/limc8h/Research/Common_Data/hg38/ENCODE-blacklist.bed"
	baseDir		= "/Volumes"
else:
	# cluster system
	genomeFa	= "/data/limlab/Resource/GenomeData/hg/hg38/Genome/genome.fa"
	chrom_size	= "/data/limlab/Resource/GenomeData/hg/hg38/Genome/chrom.size"
	#peak_mask	= "/data/limlab/Resource/GenomeData/hg/hg38/hg38-blacklist.v2.bed"
	peak_mask	= "/data/limlab/Resource/GenomeData/hg/hg38/ENCODE-blacklist.bed"
	baseDir		= "/data"

## Other essential pameters
genome			= "hg38"
adapter			= "AGATCGGAAGAGC"	# illumina universal adapter
#adapter			= "CTGTCTCTTATA"	# Nextera adapter for ATAC-seq or Cut&Tag
#trim_maxLen=100	## Maximum read length after trimming. ** NOT YET IMPLEMENTED **
trim_minLen		= 20
trim_minQual	= 20
chrRegexAll		= "^chr[0-9XY]+$"
chrRegexTarget	= "^chr[0-9XY]+$"
spikePrefix		= "NULL"

########################
## STAR index & options
star_index	= "/data/limlab/Resource/STAR_Index/hg38_allChr_v29_plusDm6"

## ChIP-seq for SE
star_option	= "--alignSJDBoverhangMin 999 --alignIntronMax 1 --outFilterMultimapNmax 1 --outFilterMismatchNoverLmax 0.05 --outReadsUnmapped None"
## Note:
## Additoinal star_option to prevent soft-clipping: "--alignEndsType EndToEnd"
## BAM sort by "--outSAMtype" is handled by the star.align.sh by -s option.
## To keep unmapped reads in the output bam file, add "--outSAMunmapped Within"

#########################
## Job flags
doTrim		= False
downSampleN	= 30000000
#doDedup		= True

#########################
## Directories
fastqDir	= "../0.Fastq"
trimDir		= "../0.Fastq.Trim"
alignDir	= "../1.1.Align"



################################
## Loading sample Information
import pandas as pd
import sys
samples = pd.read_csv(src_sampleInfo, sep="\t", comment="#", na_filter=False)
if not samples.Id.is_unique:
	print( "Error: Id column in sample.tsv is not unique")
	sys.exit()
if not samples.Name.is_unique:
	print( "Error: Name column in sample.tsv is not unique")
	sys.exit()

#################################
## Cluster configuration file
#cluster = json.load(open("./cluster.json"))
import yaml
with open('cluster.yml', 'r') as fh:
	cluster = yaml.load(fh)
#    cluster = yaml.full_load(fh)





#########################
## Rules start
#def getGroupToPool():
#	# groups that has more than one replicates
#	groupWithRep = set(samples.Group.value_counts().index[ samples.Group.value_counts() > 1 ])
#	# groups that is not input/control
#	groupNoneCtrl = set(samples.Group[samples.Ctrl != "NULL"])
#	groups = list( groupWithRep & groupNoneCtrl )
#	return groups

rule all:
	input:
		#expand("{sampleName}/TSV1", sampleName=samples.Name.tolist()),
		expand("{sampleName}/HomerPeak.factor/peak.exBL.1rpm.bed", sampleName=samples.Name[samples.PeakMode=="factor"].tolist()),
		expand("{sampleName}/HomerPeak.histone/peak.exBL.bed", sampleName=samples.Name[samples.PeakMode=="histone"].tolist()),
		expand("{sampleName}/igv.bw", sampleName=samples.Name.tolist())

include: os.environ["MY_SCRIPT_BASE"] + "/Pipeline/Snakemake.ChIP_SE/rules.pre.smk"
include: os.environ["MY_SCRIPT_BASE"] + "/Pipeline/Snakemake.ChIP_SE/rules.post.smk"
