########################
## Basic parameters

## Sample information file with five columns: id / name / group / fq1 / fq2
src_sampleInfo	= "./sample.tsv"
cluster_yml		= "~/bin/Pipeline/Snakemake/cluster.yml"

## Genome folder depending on platform: CCHMC:HPC vs my desktop
import socket
hostname = socket.gethostname()	
if( hostname == "EA19-00359" ):
	# my desktop
	genomeFa	= "/Users/limc8h/Research/Common_Data/hg38/genome/genome.fa"
	chrom_size	= "/Users/limc8h/Research/Common_Data/hg38/chrom.sizes"
	peak_mask	= "/Users/limc8h/Research/Common_Data/hg38/ENCODE-blacklist.bed"
	baseDir		= "/Volumes"
else:
	# cluster system
	genomeFa	= "/data/limlab/Resource/GenomeData/hg/hg38/Genome/genome.fa"
	chrom_size	= "/data/limlab/Resource/GenomeData/hg/hg38/Genome/chrom.size"
	peak_mask	= "/data/limlab/Resource/GenomeData/hg/hg38/hg38-blacklist.v2.bed"
	baseDir		= "/data"

## Other essential pameters
genome			= "hg38"
adapter			= "AGATCGGAAGAGC"	# illumina universal adapter
#adapter			= "CTGTCTCTTATA"	# Nextera adapter for ATAC-seq or Cut&Tag
#trim_maxLen=100	## Maximum read length after trimming. ** NOT YET IMPLEMENTED **
trim_minLen		= 20
trim_minQual	= 20
chrRegexAll		= "^chr[0-9XY]+$|^dm-chr[0-9XYLR]+$"
chrRegexTarget	= "^chr[0-9XY]+$"
spikePrefix		= "dm-"

########################
## STAR index & options
star_index	= "/data/limlab/Resource/STAR_Index/hg38_allChr_v29_plusDm6"

## ChIP-seq / ATAC-seq / Cut&Run
star_option	= "--alignSJDBoverhangMin 999 --alignIntronMax 1 --alignMatesGapMax 2000 --outFilterMultimapNmax 1 --outFilterMismatchNoverLmax 0.05 --outReadsUnmapped None"
## Note:
## Additoinal star_option to prevent soft-clipping: "--alignEndsType EndToEnd"
## BAM sort by "--outSAMtype" is handled by the star.align.sh by -s option.
## To keep unmapped reads in the output bam file, add "--outSAMunmapped Within"

#########################
## Job flags
doTrim		= False
doDedup		= True

#########################
## Directories
fastqDir	= baseDir + "/iwafuchilab/NGS_Data_NextSeq/Seq006_011320_NB501763_0325_AHVLYNBGXC_CnR.ChIP/fastq_files"
trimDir		= "0.Fastq.Trim"
alignDir	= "1.1.Align"
filteredDir	= "1.2.Align.filtered"
dedupDir	= "1.3.Align.dedup"
splitDir	= "1.4.Align.split"
fragDir		= "1.4.Align.allFrag"
baseFreqDir = filteredDir + "/BaseFreq"
fragLenDir 	= dedupDir + "/fragLenHist"
homerDir	= "3.Homer"

spikeinCntDir = fragDir0 + "/spikeinCnt"

bigWigDir_ctr_RPM	= "2.1.1.BigWig.ctr.RPM"
bigWigDir_ctr_RPM_sub	= "2.1.2.BigWig.ctr.RPM.subInput"
bigWigDir_ctr_RPM_div	= "2.1.3.BigWig.ctr.RPM.divInput"

bigWigDir_frag_RPM	= "2.2.1.BigWig.frag.RPM"
bigWigDir_frag_RPM_sub	= "2.2.2.BigWig.frag.RPM.subInput"
bigWigDir_frag_RPM_div	= "2.2.3.BigWig.frag.RPM.divInput"


bigWigDir_ctr_RPSM	= "2.3.1.BigWig.ctr.RPSM"
bigWigDir_ctr_RPSM_sub	= "2.3.2.BigWig.ctr.RPSM.subInput"
bigWigDir_ctr_RPSM_div	= "2.3.3.BigWig.ctr.RPSM.divInput"

bigWigDir_frag_RPSM	= "2.4.1.BigWig.frag.RPSM"
bigWigDir_frag_RPSM_sub	= "2.4.2.BigWig.frag.RPSM.subInput"
bigWigDir_frag_RPSM_div	= "2.4.3.BigWig.frag.RPSM.divInput"

#bigWigScaledDir	= "3.1.BigWig.scaled"
#bigWigScaledDir_sub	= "3.2.BigWig.scaled.subInput"
#bigWigScaledDir_div = "3.3.BigWig.scaled.divInput"
#bigWigAllFrag_RPSM = "3.4.BigWig.allFrag.RPSM"
#bigWigAllFrag_RPSM_subInput = "3.5.BigWig.allFrag.RPSM.subInput"

bigWigDir_sub_avg	= bigWigDir_sub + "/Avg"
bigWigScaledDir_sub_avg	= bigWigScaledDir_sub + "/Avg"
#bigWigScaledDir_div_avg	= bigWigScaledDir_div + "/Avg"

## Hetero-chromatin domain calling
peakDir 	= "PeakCall"
peakWindow 	= 2000
peakStep	= 1000
peakFC		= 2
peakAlpha	= 1
peakSuffix	= "w%d.s%d.fc%.1f" % ( peakWindow, peakStep, peakFC )

peakDir2 	= "PeakCall.Homer"
peakSuffix2	= "w%d.fc%.1f" % ( peakWindow, peakFC )

## CODE used in the initial version
#def getfq(wildcards):
#	return "0.Fastq/" + samples_indexById.loc[wildcards.sampleId, ["Fq1","Fq2"]]
#
#def getfq_trim(wildcards):
#	sampleId = samples_indexByName.loc[wildcards.sampleName, ["Id"]]
#	return [ "0.Fastq/Trim/" + sampleId + "_1.trim.fq.gz", "0.Fastq/Trim/" + sampleId + "_2.trim.fq.gz" ]

################################
## Loading sample Information
import pandas as pd
import sys
samples = pd.read_csv(src_sampleInfo, sep="\t", comment="#", na_filter=False)
if not samples.Id.is_unique:
	print( "Error: Id column in sample.tsv is not unique")
	sys.exit()
if not samples.Name.is_unique:
	print( "Error: Name column in sample.tsv is not unique")
	sys.exit()

#################################
## Cluster configuration file
#cluster = json.load(open("./cluster.json"))
import yaml
with open('cluster_yml', 'r') as fh:
	cluster = yaml.load(fh)
#    cluster = yaml.full_load(fh)






rule all:
	input:
		## output from check_baseFreq
		expand(filteredDir + "/BaseFreq/{sampleName}.R{read}.freq.png", sampleName=samples.Name.tolist(), read=[1,2]),
		## output from make_bigwig
		expand(bigWigDir_ctr_RPM + "/{sampleName}.ctr.rpm.bw", sampleName=samples.Name.tolist()),
		expand(bigWigDir_frag_RPM + "/{sampleName}.frag.rpm.bw", sampleName=samples.Name.tolist()),
		expand(bigWigDir_ctr_RPSM + "/{sampleName}.ctr.rpsm.bw", sampleName=samples.Name.tolist()),
		expand(bigWigDir_frag_RPSM + "/{sampleName}.frag.rpsm.bw", sampleName=samples.Name.tolist()),

		expand(bigWigDir_ctr_RPM_sub + "/{sampleName}.ctr.rpm.subInput.bw", sampleName=samples.Name[samples.Ctrl != "NULL"].tolist()),
		expand(bigWigDir_frag_RPM_sub + "/{sampleName}.frag.rpm.subInput.bw", sampleName=samples.Name[samples.Ctrl != "NULL"].tolist()),
		expand(bigWigDir_ctr_RPSM_sub + "/{sampleName}.ctr.rpsm.subInput.bw", sampleName=samples.Name[samples.Ctrl != "NULL"].tolist()),
		expand(bigWigDir_frag_RPSM_sub + "/{sampleName}.frag.rpsm.subInput.bw", sampleName=samples.Name[samples.Ctrl != "NULL"].tolist()),
		expand(fragLenDir + "/{sampleName}.dist.png", sampleName=samples.Name.tolist()),
#		expand(spikeinCntDir + "/{sampleName}.spikeCnt.txt", sampleName=samples.Name.tolist())
		spikeinCntDir + "/spikein.txt",
		alignDir + "/alignStat.txt"
#		expand(peakDir + "/{sampleName}.{suffix}.{ext}", sampleName=samples.Name[samples.Ctrl != "NULL"].tolist(), suffix=peakSuffix, ext=["bed","txt.gz"]),
#		expand(peakDir2 + "/{sampleName}.{suffix}.exBL.bed", sampleName=samples.Name[samples.Ctrl != "NULL"].tolist(), suffix=peakSuffix2)
		## homer tag dir
		#expand(homerDir + "/{sampleName}/TSV", sampleName=samples.Name.tolist())


include: os.environ["MY_SCRIPT_BASE"] + "/Pipeline/Snakemake/rules.pre.smk"
include: os.environ["MY_SCRIPT_BASE"] + "/Pipeline/Snakemake/rules.post.smk"
